# -*- coding: utf-8 -*-
"""gitam mini.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1m7m91C4dZZ0nZ5xuttnmsy23iVAAn-Ug

**DETECTION** **OF** **COVID**-**19** ***AT*** **EARLY** **STAGES** **USING** **DEEP** **LEARNING** **APPROACH** **ON** **LUNG** X-**RAY** **IMAGES**

---

**COLLECTING** **DATASET**
"""

!wget http://cb.lk/covid_19

!unzip covid_19

"""**IMPORTING NECESSARY LIBRARIES**"""

import keras
from keras.models import Sequential
from keras.layers import *
from keras.regularizers import l2
from keras.preprocessing import image
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ModelCheckpoint
import matplotlib.pyplot as plt
import numpy as np

"""**INITIALISING CNN MODEL**"""

model = Sequential()

model.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=(224,224,3)))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(64,(3,3),activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(128,(3,3),activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Flatten())

model.add(Dense(256,activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))

model.add(Dense(1,activation='sigmoid'))

model.compile(loss=keras.losses.binary_crossentropy,optimizer='adam',metrics=['accuracy'])

"""**PLOTTING MODEL SUMMARY**"""

from keras.utils.vis_utils import plot_model
plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)

"""**DATA** **GENERATION**"""

my_generator = ImageDataGenerator()

train_data = my_generator.flow_from_directory(
    'CovidDataset/Train',
    target_size = (224,224),
    batch_size = 15,
    class_mode = 'binary'
)


val_data = my_generator.flow_from_directory(
    'CovidDataset/Val',
    target_size = (224,224),
    batch_size = 15,
    class_mode = 'binary'
)

"""**MODELCHECKPOINT**"""

checkpointer = ModelCheckpoint(filepath="best_weights.cd",
                               monitor = 'val_accuracy',
                               verbose=1,
                               save_best_only=True)

"""**TRAINING THE MODEL**"""

cd_cnn = model.fit_generator(train_data,
                                   steps_per_epoch = 5,
                                   epochs = 10,
                                   callbacks=[checkpointer],
                                   validation_data=val_data,
                                   validation_steps = 4)

"""**LOADING THE BEST WEIGHTS**"""

model.load_weights('best_weights.cd')

"""**SAVING THE MODEL**"""

model.save('cnn.cd')

"""**PLOTTING ACCURACY AND LOSS**"""

acc = cd_cnn.history['accuracy']
val_acc = cd_cnn.history['val_accuracy']
loss = cd_cnn.history['loss']
val_loss = cd_cnn.history['val_loss']

epochs = range(1, len(acc) + 1)

plt.plot(epochs, acc, 'g', label='Train acc')
plt.plot(epochs, val_acc, 'b', label='Val acc')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training and validation accuracy')
plt.legend(['Train acc', 'Val acc'], loc='lower right')
plt.figure()

plt.plot(epochs, loss, 'g', label='Train loss')
plt.plot(epochs, val_loss, 'b', label='Val loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and validation loss')
plt.legend(['Train loss', 'Val loss'], loc='upper right')
plt.figure()

"""**EVALUATING THE MODEL**"""

model.evaluate_generator(train_data)

model.evaluate_generator(val_data)

"""**TESTING THE MODEL ON VALIDATION DATA**

---




"""

y_actual = []
y_test = []

import os

for i in os.listdir("./CovidDataset/Val/Normal/"):
  img = image.load_img("./CovidDataset/Val/Normal/"+i, target_size=(224,224))
  img = image.img_to_array(img)
  img = np.expand_dims(img, axis=0)
  p = model.predict(img)
  y_test.append(p[0,0])
  y_actual.append(1)

for i in os.listdir("./CovidDataset/Val/Covid/"):
  img = image.load_img("./CovidDataset/Val/Covid/"+i, target_size=(224,224))
  img = image.img_to_array(img)
  img = np.expand_dims(img, axis=0)
  p = model.predict(img)
  y_test.append(p[0,0])
  y_actual.append(0)

y_actual = np.array(y_actual)
y_test = np.array(y_test)

from sklearn.metrics import confusion_matrix

y_test.shape

cm = confusion_matrix(y_test, y_actual)

import seaborn as sns

sns.heatmap(cm, cmap="plasma", annot=True)

